{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/LLM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-05 12:34:09,113] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.68s/it]\n"
     ]
    }
   ],
   "source": [
    "from cad import CAD\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "model_name = \"/root/share/Llama-2-13b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16, )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, padding_side=\"left\", )\n",
    "tokenizer.pad_token_id = 0 if tokenizer.pad_token_id is None else tokenizer.pad_token_id\n",
    "tokenizer.bos_token_id = 1\n",
    "cad = CAD(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MemoTrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Better late than\"\n",
    "c = 'Write a quote that ends in word \"early\": '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never, I suppose.\\nI\\'m not sure if it was the right decision to make, but at least now we have a chance to move forward and try to win some games. We need to focus on our own play and stop worrying about what other teams are doing. If we can do that, then maybe we can start turning things around.\"']\n"
     ]
    }
   ],
   "source": [
    "raw_output = cad.generate(\n",
    "    texts=x,\n",
    ")\n",
    "\n",
    "print(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"never right?\\nI have been following the story of the Higgs boson for a while now, and I must say that it is quite fascinating. The idea that there could be a particle that gives other particles mass just blows my mind! It's like, wow, how can something so small have such an enormous impact on everything around us?\\nAnyway, enough about that. On to more important matters...like cats! ðŸ± Have you seen any good cat videos lately? I am always on the lookout for new ones to watch. My favorite will always be Grumpy Cat though - she just cracks me up every time! ðŸ˜¹\"]\n"
     ]
    }
   ],
   "source": [
    "conditioned_output = cad.generate(\n",
    "    texts=x,\n",
    "    texts_with_context=c+x,\n",
    ")\n",
    "\n",
    "print(conditioned_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
