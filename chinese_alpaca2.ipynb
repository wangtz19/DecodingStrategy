{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/LLM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-05 12:18:12,490] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:19<00:00,  6.58s/it]\n",
      "/opt/conda/envs/LLM/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/LLM/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from cad import CAD\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "model_name = \"/root/share/chinese-alpaca-2-13b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16, )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, padding_side=\"left\", )\n",
    "cad = CAD(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are a helpful assistant. 你是一个乐于助人的助手。\n",
      "<</SYS>>\n",
      "\n",
      "【已知】：【\"项目名称\"：2022年工业互联网标识解析二级节点建设奖励\n",
      "审批流程：无。】\n",
      "你现在是一个政企领域的专家，基于【已知】给的多个内容，请回答问题：“2022年工业互联网标识解析二级节点建设奖励的审批流程是什么？”，一定要保证答案正确！[/INST]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"[INST] <<SYS>>\n",
    "You are a helpful assistant. 你是一个乐于助人的助手。\n",
    "<</SYS>>\n",
    "\n",
    "【已知】：【\"项目名称\"：{title}\n",
    "{label}：{content}】\n",
    "你现在是一个政企领域的专家，基于【已知】给的多个内容，请回答问题：“{question}”，一定要保证答案正确！[/INST]\"\"\"\n",
    "\n",
    "df = pd.read_json(\"/root/share/scripts/output/intent-chatglm3-6b-optimize.json\")\n",
    "row = df.loc[0]\n",
    "question = row[\"一般提问\"]\n",
    "prompt = PROMPT_TEMPLATE.format(\n",
    "    title=row[\"title\"],\n",
    "    label=row[\"二级policy预测\"],\n",
    "    content=row[\"content\"],\n",
    "    question=row[\"一般提问\"],\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['根据【已知】的内容，2022年工业互联网标识解析二级节点建设奖励的审批流程是无。也就是说，没有具体的审批程序或步骤需要进行申请和审核的过程。']\n"
     ]
    }
   ],
   "source": [
    "outputs_no_cad = cad.generate(\n",
    "    texts=[prompt],\n",
    "    max_new_tokens=200,\n",
    ")\n",
    "print(outputs_no_cad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n答：工业和信息化部会同有关部门制定《关于做好2019年-2022年全国性行业级标识解析二级节点建设工作的通知》（工信厅〔2018〕36号）。 根据该文件，省级通信管理局负责组织本地区的相关工作并向本部门提出申请；国家互联网信息办公室对符合条件的应用进行审核后报国务院办公厅批准发布公告。']\n"
     ]
    }
   ],
   "source": [
    "outputs = cad.generate(\n",
    "    texts=[question],\n",
    "    texts_with_context=[prompt],\n",
    "    max_new_tokens=200,\n",
    ")\n",
    "\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
